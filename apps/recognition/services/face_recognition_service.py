import face_recognition
import numpy as np
import tempfile
from PIL import Image
from deepface import DeepFace
from apps.recognition.models.person import Person, FaceImage
from sklearn.metrics.pairwise import cosine_similarity

class FaceRecognitionService:

    def get_embedding(self, image_file):
        print("ğŸ” [1] Procesando imagen con face_recognition...")
        try:
            # Preparar imagen
            img = Image.open(image_file)
            img = img.convert("RGB")
            img = img.resize((640, 640))

            with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
                img.save(tmp.name)
                image_np = face_recognition.load_image_file(tmp.name)

            # Embedding
            face_locations = face_recognition.face_locations(image_np, model='cnn')
            if not face_locations:
                print("âŒ No se detectÃ³ ninguna cara.")
                return None

            encodings = face_recognition.face_encodings(image_np, face_locations)
            if not encodings:
                print("âŒ No se pudo calcular el encoding.")
                return None

            # [ğŸ§ ] PredicciÃ³n real de edad y gÃ©nero
            print("ğŸ“Š [2] Obteniendo edad y gÃ©nero reales...")
            analysis = DeepFace.analyze(
                img_path=tmp.name,
                actions=["age", "gender"],
                enforce_detection=False
            )[0]


            edad = int(analysis["age"])
            genero = analysis["gender"]

            print(f"âœ… Embedding OK | Edad: {edad}, GÃ©nero: {genero}")
            return encodings[0].tolist(), edad, genero

        except Exception as e:
            print("âŒ Error procesando imagen:", e)
            return None

    def find_best_match(self, embedding, threshold=0.4):
        all_images = FaceImage.objects.select_related('person').all()
        best_match = None
        best_score = -1

        if embedding is None:
            return None

        print(f"\nğŸ” Comparando con {len(all_images)} imÃ¡genes guardadas...\n")

        for face_image in all_images:
            if face_image.embedding:
                stored_embedding = np.array(face_image.embedding)

                print(f"â†ªï¸ {face_image.person.nombre} {face_image.person.apellidos}")
                print(f"   ğŸ§¬ Dimensiones: actual={len(embedding)} vs guardado={stored_embedding.shape[0]}")

                if stored_embedding.shape[0] != len(embedding):
                    print("   âš ï¸ Ignorado por longitud incompatible.\n")
                    continue

                sim = cosine_similarity([embedding], [stored_embedding])[0][0]
                print(f"   ğŸ“Š Similitud: {sim:.4f}")

                if sim > best_score and sim >= threshold:
                    best_score = sim
                    best_match = face_image.person
                    print("   âœ… Â¡Posible mejor coincidencia!\n")
                else:
                    print("   âŒ Debajo del umbral\n")

        if best_match:
            print(f"ğŸ¯ Coincidencia final: {best_match.nombre} con similitud {best_score:.4f}")
        else:
            print("âŒ No se encontrÃ³ ninguna coincidencia suficientemente similar.")

        return best_match
